================================================================================
FILE: dkg\__init__.py
================================================================================


================================================================================
FILE: dkg\parsers\__init__.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from abc import ABC, abstractmethod
   4: from typing import Dict
   5: 
   6: from ..graph import DKGEdge, DKGNode
   7: from ..graph_updater import GraphUpdater
   8: from ..stages import ParsingStage
   9: 
  10: 
  11: class ConstraintParser(ABC):
  12:     """제약 파일 파서 베이스 클래스"""
  13:     
  14:     @abstractmethod
  15:     def get_stage(self) -> ParsingStage:
  16:         """이 파서가 속한 stage 반환"""
  17:         pass
  18:     
  19:     @abstractmethod
  20:     def parse_and_update(
  21:         self,
  22:         filepath: str,
  23:         updater: GraphUpdater,
  24:         nodes: Dict[str, DKGNode],
  25:         edges: Dict[str, DKGEdge],
  26:     ) -> None:
  27:         """
  28:         파일을 파싱하고 그래프를 업데이트.
  29:         
  30:         Args:
  31:             filepath: 파싱할 파일 경로
  32:             updater: GraphUpdater 인스턴스
  33:             nodes: 기존 노드 딕셔너리
  34:             edges: 기존 엣지 딕셔너리
  35:         """
  36:         pass


================================================================================
FILE: main.py
================================================================================
   1: from __future__ import annotations
   2: from dkg.config import YosysConfig
   3: from dkg.debug import (
   4:     plot_subgraph,
   5:     print_fanout_summary,
   6:     print_graph_summary,
   7:     print_sample_node,
   8:     trace_signal,
   9: )
  10: from dkg.graph_build import build_nodes_and_edges, build_wires_and_cells
  11: from dkg.yosys_parser import parse_yosys
  12: 
  13: 
  14: DEFAULT_CONFIG = YosysConfig(
  15:     src_dir_win=r"C:\Users\User\NetMind\구현\예시",
  16:     out_json_win=r"C:\Users\User\NetMind\구현\design.json",
  17:     top_module="riscvsingle",
  18: )
  19: 
  20: 
  21: def main(config: YosysConfig, debug: bool = True) -> None:
  22:     yosys = parse_yosys(config)
  23:     wires, cells = build_wires_and_cells(yosys)
  24:     nodes, edges = build_nodes_and_edges(wires, cells)
  25: 
  26:     if debug:
  27:         print_graph_summary(wires, cells, nodes, edges)
  28:         print_sample_node(nodes, edges)
  29:         print_fanout_summary(wires)
  30:         trace_signal(wires, "clk")
  31:         plot_subgraph(nodes, edges, limit=30)
  32: 
  33: 
  34: if __name__ == "__main__":
  35:     main(DEFAULT_CONFIG, debug=True)


================================================================================
FILE: AICollector.py
================================================================================
   1: from pathlib import Path
   2: 
   3: def collect_py_files(output_txt: str = "result.txt"):
   4:     base_path = Path(__file__).parent
   5:     py_files = list(base_path.rglob("*.py"))
   6: 
   7:     def sort_key(path: Path):
   8:         name = path.name.lower()
   9:         if name == "__init__.py":
  10:             return (0, str(path))
  11:         if name == "main.py":
  12:             return (1, str(path))
  13:         return (2, str(path))
  14: 
  15:     py_files.sort(key=sort_key)
  16: 
  17:     with open(output_txt, "w", encoding="utf-8") as out:
  18:         for py_file in py_files:
  19:             relative_path = py_file.relative_to(base_path)
  20: 
  21:             out.write("=" * 80 + "\n")
  22:             out.write(f"FILE: {relative_path}\n")
  23:             out.write("=" * 80 + "\n")
  24: 
  25:             try:
  26:                 with open(py_file, "r", encoding="utf-8") as f:
  27:                     for idx, line in enumerate(f, start=1):
  28:                         out.write(f"{idx:4d}: {line}")
  29:             except Exception as e:
  30:                 out.write(f"[ERROR] 파일을 읽을 수 없습니다: {e}\n")
  31: 
  32:             out.write("\n\n")
  33: 
  34: 
  35: if __name__ == "__main__":
  36:     collect_py_files()


================================================================================
FILE: dkg\config.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from dataclasses import dataclass
   4: 
   5: 
   6: @dataclass
   7: class YosysConfig:
   8:     src_dir_win: str
   9:     out_json_win: str
  10:     top_module: str


================================================================================
FILE: dkg\debug.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: import random
   4: from typing import Dict, Iterable, List
   5: 
   6: from .graph import DKGEdge, DKGNode
   7: from .ir import CellIR, Wire
   8: 
   9: 
  10: def print_graph_summary(wires: Dict[int, Wire], cells: List[CellIR], nodes: Dict[str, DKGNode], edges: Dict[str, DKGEdge]) -> None:
  11:     print("===== GRAPH SUMMARY =====")
  12:     print(f"Total wires   : {len(wires)}")
  13:     print(f"Total cells   : {len(cells)}")
  14:     print(f"Total nodes   : {len(nodes)}")
  15:     print(f"Total edges   : {len(edges)}")
  16:     print("=========================")
  17: 
  18: 
  19: def print_sample_node(nodes: Dict[str, DKGNode], edges: Dict[str, DKGEdge], max_edges: int = 5) -> None:
  20:     if not nodes:
  21:         print("No nodes available.")
  22:         return
  23: 
  24:     sample = random.choice(list(nodes.values()))
  25:     print("\n===== SAMPLE NODE =====")
  26:     print("Node:", sample.node_id, sample.entity_class)
  27:     print("IN edges:", len(sample.in_edges))
  28:     print("OUT edges:", len(sample.out_edges))
  29: 
  30:     for eid in sample.out_edges[:max_edges]:
  31:         e = edges[eid]
  32:         print("  ->", e.signal_name, "->", e.dst_node)
  33:     print("=========================")
  34: 
  35: 
  36: def print_fanout_summary(wires: Dict[int, Wire]) -> None:
  37:     fanouts = [len(w.loads) for w in wires.values() if w.loads]
  38:     if not fanouts:
  39:         print("\nMax fanout: 0")
  40:         print("Avg fanout: 0")
  41:         print("=========================")
  42:         return
  43: 
  44:     print("\nMax fanout:", max(fanouts))
  45:     print("Avg fanout:", sum(fanouts) / len(fanouts))
  46:     print("=========================")
  47: 
  48: 
  49: def trace_signal(wires: Dict[int, Wire], target: str) -> None:
  50:     print("\n===== TRACE SIGNAL:", target, "=====")
  51:     for w in wires.values():
  52:         if w.name == target:
  53:             print("Drivers:", w.drivers)
  54:             print("Loads  :", w.loads)
  55:     print("=========================")
  56: 
  57: 
  58: def plot_subgraph(nodes: Dict[str, DKGNode], edges: Dict[str, DKGEdge], limit: int = 30) -> None:
  59:     try:
  60:         import networkx as nx
  61:         import matplotlib.pyplot as plt
  62:     except Exception as exc:
  63:         print("Plot skipped:", exc)
  64:         return
  65: 
  66:     g = nx.DiGraph()
  67:     for nid in nodes:
  68:         g.add_node(nid)
  69: 
  70:     for e in edges.values():
  71:         g.add_edge(e.src_node, e.dst_node, label=e.signal_name)
  72: 
  73:     sub_nodes = list(nodes.keys())[:limit]
  74: 
  75:     def clean_label(name: str) -> str:
  76:         return name.replace("\\", "").replace("$", "")
  77: 
  78:     h = g.subgraph(sub_nodes)
  79:     labels = {n: clean_label(n) for n in h.nodes()}
  80: 
  81:     nx.draw(h, labels=labels, with_labels=True, node_size=500, font_size=6)
  82:     plt.show()


================================================================================
FILE: dkg\graph.py
================================================================================
   1: # NOTE:
   2: # canonical_name is a human-readable debug label.
   3: # It is intended for debugging, tracing, and debug-like queries only.
   4: # It is NOT guaranteed to be stable across views, abstractions, or builds,
   5: # and MUST NOT be used as a persistent identifier, cache key, or external reference.
   6: from __future__ import annotations
   7: 
   8: from dataclasses import dataclass, field
   9: from enum import Enum
  10: from typing import Any, Dict, List, Optional, Tuple
  11: 
  12: from .provenance import Provenance
  13: 
  14: 
  15: class EntityClass(str, Enum):
  16:     MODULE_INSTANCE = "ModuleInstance"
  17:     RTL_BLOCK = "RTLBlock"
  18:     FSM = "FSM"
  19: 
  20:     FLIP_FLOP = "FlipFlop"
  21:     LUT = "LUT"
  22:     MUX = "MUX"
  23:     DSP = "DSP"
  24:     BRAM = "BRAM"
  25: 
  26:     IO_PORT = "IOPort"
  27:     PACKAGE_PIN = "PackagePin"
  28:     PBLOCK = "Pblock"
  29:     BOARD_CONNECTOR = "BoardConnector"
  30: 
  31: 
  32: class RelationType(str, Enum):
  33:     DATA = "DataRelation"
  34:     CLOCK = "ClockRelation"
  35:     RESET = "ResetRelation"
  36:     PARAMETER = "ParameterRelation"
  37:     CONSTRAINT = "ConstraintRelation"
  38:     PHYSICAL_MAP = "PhysicalMappingRelation"
  39: 
  40: 
  41: class EdgeFlowType(str, Enum):
  42:     COMBINATIONAL = "combinational"
  43:     SEQ_LAUNCH = "sequential_launch"
  44:     SEQ_CAPTURE = "sequential_capture"
  45:     CLOCK_TREE = "clock_tree"
  46:     ASYNC_RESET = "async_reset"
  47: 
  48: 
  49: @dataclass
  50: class DKGNode:
  51:     # 핵심 식별자 (영구적, 안정적)
  52:     node_id: str
  53:     entity_class: EntityClass
  54:     hier_path: str
  55:     local_name: str
  56:     canonical_name: Optional[str] = None
  57: 
  58:     # 메타데이터
  59:     parameters: Dict[str, str] = field(default_factory=dict)
  60:     attributes: Dict[str, str] = field(default_factory=dict)
  61: 
  62:     clock_domain: Optional[str] = None
  63:     arrival_time: Optional[float] = None
  64:     required_time: Optional[float] = None
  65:     slack: Optional[float] = None
  66: 
  67:     in_edges: List[str] = field(default_factory=list)
  68:     out_edges: List[str] = field(default_factory=list)
  69: 
  70:     provenances: List[Provenance] = field(default_factory=list)
  71:     primary_provenance: Optional[Provenance] = None
  72: 
  73: 
  74: @dataclass
  75: class DKGEdge:
  76:     edge_id: str
  77:     src_node: str
  78:     dst_node: str
  79: 
  80:     relation_type: RelationType
  81:     flow_type: EdgeFlowType
  82: 
  83:     signal_name: str
  84:     canonical_name: str
  85:     bit_range: Optional[Tuple[int, int]] = None
  86:     net_id: Optional[str] = None
  87: 
  88:     driver_type: Optional[str] = None
  89:     fanout_count: Optional[int] = None
  90: 
  91:     clock_signal: Optional[str] = None
  92:     reset_signal: Optional[str] = None
  93:     clock_domain_id: Optional[str] = None
  94: 
  95:     timing_exception: Optional[str] = None
  96:     parameters: Dict[str, Any] = field(default_factory=dict)
  97: 
  98:     delay: Optional[float] = None
  99:     arrival_time: Optional[float] = None
 100:     required_time: Optional[float] = None
 101:     slack: Optional[float] = None
 102: 
 103:     attributes: Dict[str, Any] = field(default_factory=dict)
 104: 
 105:     provenances: List[Provenance] = field(default_factory=list)
 106:     primary_provenance: Optional[Provenance] = None
 107: 
 108: 
 109: def make_node_canonical_name(node: DKGNode) -> str:
 110:     base = node.hier_path
 111: 
 112:     cls = node.entity_class
 113:     if cls == EntityClass.FLIP_FLOP:
 114:         suffix = f"reg_{node.local_name}"
 115:     elif cls == EntityClass.MUX:
 116:         suffix = "mux"
 117:     elif cls == EntityClass.LUT:
 118:         suffix = "comb"
 119:     elif cls == EntityClass.BRAM:
 120:         suffix = "bram"
 121:     elif cls == EntityClass.DSP:
 122:         suffix = "dsp"
 123:     elif cls == EntityClass.IO_PORT:
 124:         suffix = f"port_{node.local_name}"
 125:     else:
 126:         suffix = node.local_name or cls.value.lower()
 127: 
 128:     return f"{base}.{suffix}"
 129: 
 130: 
 131: def make_node_display_name(node: DKGNode, lang: str = "en") -> str:
 132:     """
 133:     노드의 디스플레이 이름 생성 (UI용).
 134:     
 135:     Args:
 136:         node: DKGNode 인스턴스
 137:         lang: 언어 ('en', 'ko' 등)
 138:     
 139:     Returns:
 140:         사람이 읽기 좋은 이름
 141:     
 142:     Note:
 143:         DKG 데이터 모델 자체에 저장되지 않음.
 144:         필요할 때만 on-demand로 생성 (presentation layer 책임).
 145:     """
 146:     display_map = {
 147:         'en': {
 148:             EntityClass.FLIP_FLOP: f"Reg {node.local_name}",
 149:             EntityClass.BRAM: "BRAM",
 150:             EntityClass.MUX: "MUX",
 151:             EntityClass.LUT: "Logic",
 152:             EntityClass.DSP: "DSP",
 153:             EntityClass.IO_PORT: f"Port {node.local_name}",
 154:         },
 155:         'ko': {
 156:             EntityClass.FLIP_FLOP: f"레지스터 {node.local_name}",
 157:             EntityClass.BRAM: "메모리",
 158:             EntityClass.MUX: "멀티플렉서",
 159:             EntityClass.LUT: "조합논리",
 160:             EntityClass.DSP: "디지털신호처리",
 161:             EntityClass.IO_PORT: f"포트 {node.local_name}",
 162:         },
 163:     }
 164:     
 165:     lang_map = display_map.get(lang, display_map['en'])
 166:     return lang_map.get(
 167:         node.entity_class,
 168:         node.local_name or node.entity_class.value
 169:     )
 170: 
 171: 
 172: def make_edge_canonical_name(e: DKGEdge, nodes: dict[str, DKGNode]) -> str:
 173:     src = nodes[e.src_node].canonical_name
 174:     dst = nodes[e.dst_node].canonical_name
 175: 
 176:     if e.bit_range:
 177:         msb, lsb = e.bit_range
 178:         sig = f"{e.signal_name}[{msb}:{lsb}]"
 179:     else:
 180:         sig = e.signal_name
 181: 
 182:     return f"{src} -> {dst} : {sig}"
 183: 
 184: 
 185: def make_edge_display_name(e: DKGEdge) -> str:
 186:     if e.bit_range:
 187:         msb, lsb = e.bit_range
 188:         return f"{e.signal_name}[{msb}:{lsb}]"
 189:     return e.signal_name


================================================================================
FILE: dkg\graph_build.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from collections import defaultdict
   4: from typing import Dict, Iterable, List, Optional, Tuple
   5: 
   6: from .graph import (
   7:     DKGEdge,
   8:     DKGNode,
   9:     EdgeFlowType,
  10:     EntityClass,
  11:     RelationType,
  12:     make_node_canonical_name,
  13: )
  14: from .ir import CellIR, Wire
  15: from .provenance import Provenance, add_provenance, merge_provenances_edges
  16: from .utils import (
  17:     is_active_low,
  18:     is_clock_name,
  19:     is_reset_name,
  20:     parse_src,
  21:     split_signal_bit,
  22:     stable_hash,
  23: )
  24: 
  25: 
  26: def get_wire(wires: Dict[int, Wire], wid) -> Optional[Wire]:
  27:     if isinstance(wid, str):
  28:         return None
  29:     if wid not in wires:
  30:         wires[wid] = Wire(wid)
  31:     return wires[wid]
  32: 
  33: 
  34: def build_wires_and_cells(yosys: dict) -> Tuple[Dict[int, Wire], List[CellIR]]:
  35:     wires: Dict[int, Wire] = {}
  36:     cells: List[CellIR] = []
  37: 
  38:     for mod in yosys.get("modules", {}).values():
  39:         for netname, netinfo in mod.get("netnames", {}).items():
  40:             src = netinfo.get("src")
  41:             for wid in netinfo.get("bits", []):
  42:                 w = get_wire(wires, wid)
  43:                 if w:
  44:                     w.name = netname
  45:                     w.src = src
  46: 
  47:     for mod_name, mod in yosys.get("modules", {}).items():
  48:         for cname, c in mod.get("cells", {}).items():
  49:             cells.append(
  50:                 CellIR(
  51:                     name=cname,
  52:                     type=c["type"],
  53:                     module=mod_name,
  54:                     port_dirs=c["port_directions"],
  55:                     connections=c["connections"],
  56:                     src=c.get("src"),
  57:                 )
  58:             )
  59: 
  60:     return wires, cells
  61: 
  62: 
  63: def map_cell_type(t: str) -> EntityClass:
  64:     if t in ["$adff", "$dff"]:
  65:         return EntityClass.FLIP_FLOP
  66:     if t in ["$mux", "$pmux"]:
  67:         return EntityClass.MUX
  68:     if t in ["$add", "$sub", "$and", "$or"]:
  69:         return EntityClass.RTL_BLOCK
  70:     return EntityClass.RTL_BLOCK
  71: 
  72: 
  73: def cell_signature(cell: CellIR) -> str:
  74:     ports = sorted(
  75:         f"{p}:{cell.port_dirs[p]}:{len(bits)}"
  76:         for p, bits in cell.connections.items()
  77:     )
  78:     return "|".join(
  79:         [
  80:             cell.type,
  81:             cell.module,
  82:             ",".join(ports),
  83:         ]
  84:     )
  85: 
  86: 
  87: def signal_signature(e: DKGEdge) -> str:
  88:     if e.bit_range:
  89:         msb, lsb = e.bit_range
  90:         return f"{e.signal_name}[{msb}:{lsb}]"
  91:     return e.signal_name
  92: 
  93: 
  94: def edge_signature(e: DKGEdge) -> str:
  95:     return "|".join(
  96:         [
  97:             e.src_node,
  98:             e.dst_node,
  99:             e.relation_type.value,
 100:             e.flow_type.value,
 101:             signal_signature(e),
 102:         ]
 103:     )
 104: 
 105: 
 106: def make_edge_id(e: DKGEdge) -> str:
 107:     sig = edge_signature(e)
 108:     h = stable_hash(sig)
 109:     return f"E_{e.relation_type.value}_{h}"
 110: 
 111: 
 112: def make_node_id(cell: CellIR) -> str:
 113:     sig = cell_signature(cell)
 114:     return f"N_{map_cell_type(cell.type).value}_{stable_hash(sig)}"
 115: 
 116: 
 117: def connect_wires_to_cells(wires: Dict[int, Wire], cells: Iterable[CellIR]) -> None:
 118:     cell_id_map: Dict[str, str] = {}
 119:     for cell in cells:
 120:         cell_key = f"{cell.module}.{cell.name}"
 121:         cell_id_map[cell_key] = make_node_id(cell)
 122: 
 123:     for cell in cells:
 124:         node_id = cell_id_map[f"{cell.module}.{cell.name}"]
 125:         for port, bits in cell.connections.items():
 126:             direction = cell.port_dirs[port]
 127:             for wid in bits:
 128:                 w = get_wire(wires, wid)
 129:                 if not w:
 130:                     continue
 131:                 if direction == "output":
 132:                     w.drivers.append(node_id)
 133:                 else:
 134:                     w.loads.append(node_id)
 135: 
 136: 
 137: def detect_clock_reset_from_ff_cells(
 138:     cells: List[CellIR],
 139:     wires: Dict[int, Wire],
 140: ) -> Tuple[set[str], set[str]]:
 141:     """
 142:     Yosys FF cell 포트 정보에서 clock/reset 신호 직접 추출.
 143:     
 144:     구조적 분석을 통해 신뢰도 높은 식별:
 145:     - $dff, $adff, $sdff 등의 CLK 포트 → clock
 146:     - ARST, SRST 포트 → reset
 147:     """
 148:     clock_nets: set[str] = set()
 149:     reset_nets: set[str] = set()
 150:     
 151:     # FF cell 타입 정의
 152:     ff_cell_types = {
 153:         "$dff", "$adff", "$sdff",
 154:         "$dffe", "$sdffe", "$aldff", "$aldffe",
 155:     }
 156:     
 157:     for cell in cells:
 158:         if cell.type not in ff_cell_types:
 159:             continue
 160:         
 161:         # CLK 포트 찾기
 162:         if "CLK" in cell.connections:
 163:             clk_wids = cell.connections["CLK"]
 164:             for wid in clk_wids:
 165:                 w = get_wire(wires, wid)
 166:                 if w and w.name:
 167:                     clock_nets.add(w.name)
 168:         
 169:         # 비동기 리셋 포트 (ARST, ARST_N 등)
 170:         async_reset_ports = {"ARST", "ARST_N", "NRST", "NRESET"}
 171:         for port in async_reset_ports:
 172:             if port in cell.connections:
 173:                 rst_wids = cell.connections[port]
 174:                 for wid in rst_wids:
 175:                     w = get_wire(wires, wid)
 176:                     if w and w.name:
 177:                         reset_nets.add(w.name)
 178:         
 179:         # 동기 리셋 포트 (SRST, SRST_N 등)
 180:         sync_reset_ports = {"SRST", "SRST_N", "SR", "R", "RST"}
 181:         for port in sync_reset_ports:
 182:             if port in cell.connections:
 183:                 rst_wids = cell.connections[port]
 184:                 for wid in rst_wids:
 185:                     w = get_wire(wires, wid)
 186:                     if w and w.name:
 187:                         reset_nets.add(w.name)
 188:     
 189:     return clock_nets, reset_nets
 190: 
 191: 
 192: def detect_clock_reset_signals(
 193:     nodes: Dict[str, DKGNode],
 194:     edges: Dict[str, DKGEdge],
 195:     cells: List[CellIR],
 196:     wires: Dict[int, Wire],
 197: ) -> Tuple[set[str], set[str]]:
 198:     """
 199:     Clock/Reset 신호 식별 (다단계 우선순위).
 200:     
 201:     1️⃣ 구조적 분석: FF cell 포트 정보 (높은 신뢰도)
 202:     2️⃣ 신호 분석: edge의 flow 정보
 203:     3️⃣ 이름 기반 휴리스틱: 패턴 매칭 (낮은 신뢰도)
 204:     """
 205:     # Stage 1: 구조적 분석 (FF cell 포트)
 206:     clock_nets, reset_nets = detect_clock_reset_from_ff_cells(cells, wires)
 207:     
 208:     # Stage 2: 엣지 신호 이름 기반 (추론)
 209:     for e in edges.values():
 210:         if is_clock_name(e.signal_name):
 211:             clock_nets.add(e.signal_name)
 212:         if is_reset_name(e.signal_name):
 213:             reset_nets.add(e.signal_name)
 214:     
 215:     # Stage 3: FF 입력 신호 확인 (구조적 재검증)
 216:     for n in nodes.values():
 217:         if n.entity_class != EntityClass.FLIP_FLOP:
 218:             continue
 219:         for eid in n.in_edges:
 220:             e = edges[eid]
 221:             # 이미 식별된 것은 확인, 아니면 추가 확인
 222:             if is_clock_name(e.signal_name) and e.signal_name not in clock_nets:
 223:                 clock_nets.add(e.signal_name)
 224:             if is_reset_name(e.signal_name) and e.signal_name not in reset_nets:
 225:                 reset_nets.add(e.signal_name)
 226:     
 227:     return clock_nets, reset_nets
 228: 
 229: 
 230: def assign_edge_flow_types(
 231:     nodes: Dict[str, DKGNode],
 232:     edges: Dict[str, DKGEdge],
 233:     clock_nets: set[str],
 234:     reset_nets: set[str],
 235: ) -> None:
 236:     for e in edges.values():
 237:         if e.signal_name in clock_nets:
 238:             e.flow_type = EdgeFlowType.CLOCK_TREE
 239:             continue
 240:         if e.signal_name in reset_nets:
 241:             e.flow_type = EdgeFlowType.ASYNC_RESET
 242:             continue
 243: 
 244:         src = nodes[e.src_node]
 245:         dst = nodes[e.dst_node]
 246: 
 247:         if src.entity_class == EntityClass.FLIP_FLOP:
 248:             e.flow_type = EdgeFlowType.SEQ_LAUNCH
 249:         elif dst.entity_class == EntityClass.FLIP_FLOP:
 250:             e.flow_type = EdgeFlowType.SEQ_CAPTURE
 251:         else:
 252:             e.flow_type = EdgeFlowType.COMBINATIONAL
 253: 
 254: 
 255: def assign_clock_domains(
 256:     nodes: Dict[str, DKGNode],
 257:     edges: Dict[str, DKGEdge],
 258:     clock_nets: set[str],
 259: ) -> None:
 260:     for n in nodes.values():
 261:         if n.entity_class != EntityClass.FLIP_FLOP:
 262:             continue
 263:         for eid in n.in_edges:
 264:             e = edges[eid]
 265:             if e.signal_name in clock_nets:
 266:                 n.clock_domain = e.signal_name
 267:                 break
 268: 
 269: 
 270: def merge_bit_edges_to_bus(edges: Dict[str, DKGEdge]) -> Dict[str, DKGEdge]:
 271:     groups: Dict[Tuple[str, str, RelationType, EdgeFlowType, str], List[Tuple[Optional[int], DKGEdge]]] = defaultdict(list)
 272: 
 273:     for e in edges.values():
 274:         base, bit = split_signal_bit(e.signal_name)
 275:         key = (e.src_node, e.dst_node, e.relation_type, e.flow_type, base)
 276:         groups[key].append((bit, e))
 277: 
 278:     new_edges: Dict[str, DKGEdge] = {}
 279:     new_eid = 0
 280: 
 281:     for key, items in groups.items():
 282:         _, _, _, _, base = key
 283: 
 284:         if all(bit is None for bit, _ in items):
 285:             for _, e in items:
 286:                 new_edges[e.edge_id] = e
 287:             continue
 288: 
 289:         items.sort(key=lambda x: (-1 if x[0] is None else x[0]))
 290: 
 291:         current_bucket: List[Tuple[Optional[int], DKGEdge]] = []
 292:         prev_bit: Optional[int] = None
 293: 
 294:         def flush_bucket(bucket: List[Tuple[Optional[int], DKGEdge]]) -> None:
 295:             nonlocal new_eid
 296:             if not bucket:
 297:                 return
 298: 
 299:             bits = [b for b, _ in bucket if b is not None]
 300:             edges_in_bucket = [e for _, e in bucket]
 301: 
 302:             if len(bits) <= 1:
 303:                 e = edges_in_bucket[0]
 304:                 new_edges[e.edge_id] = e
 305:                 return
 306: 
 307:             msb = max(bits)
 308:             lsb = min(bits)
 309:             base_edge = edges_in_bucket[0]
 310:             merged = DKGEdge(
 311:                 edge_id=f"bus_e{new_eid}",
 312:                 src_node=base_edge.src_node,
 313:                 dst_node=base_edge.dst_node,
 314:                 relation_type=base_edge.relation_type,
 315:                 flow_type=base_edge.flow_type,
 316:                 signal_name=f"{base}[{msb}:{lsb}]",
 317:                 canonical_name=base_edge.canonical_name,
 318:                 bit_range=(msb, lsb),
 319:                 net_id=base_edge.net_id,
 320:                 driver_type=base_edge.driver_type,
 321:                 fanout_count=base_edge.fanout_count,
 322:                 clock_signal=base_edge.clock_signal,
 323:                 reset_signal=base_edge.reset_signal,
 324:                 clock_domain_id=base_edge.clock_domain_id,
 325:                 timing_exception=base_edge.timing_exception,
 326:                 delay=base_edge.delay,
 327:                 arrival_time=base_edge.arrival_time,
 328:                 required_time=base_edge.required_time,
 329:                 slack=base_edge.slack,
 330:                 attributes=dict(base_edge.attributes),
 331:                 provenances=[],
 332:                 primary_provenance=None,
 333:             )
 334: 
 335:             primary, provs = merge_provenances_edges(edges_in_bucket)
 336:             merged.provenances = provs
 337:             merged.primary_provenance = primary
 338:             merged.attributes["merged_bits"] = sorted(bits)
 339: 
 340:             new_edges[merged.edge_id] = merged
 341:             new_eid += 1
 342: 
 343:         for bit, e in items:
 344:             if bit is None:
 345:                 flush_bucket(current_bucket)
 346:                 current_bucket = []
 347:                 new_edges[e.edge_id] = e
 348:                 prev_bit = None
 349:                 continue
 350: 
 351:             if prev_bit is None or bit == prev_bit - 1:
 352:                 current_bucket.append((bit, e))
 353:             else:
 354:                 flush_bucket(current_bucket)
 355:                 current_bucket = [(bit, e)]
 356: 
 357:             prev_bit = bit
 358: 
 359:         flush_bucket(current_bucket)
 360: 
 361:     return new_edges
 362: 
 363: 
 364: def reindex_node_edges(nodes: Dict[str, DKGNode], edges: Dict[str, DKGEdge]) -> None:
 365:     for n in nodes.values():
 366:         n.in_edges = []
 367:         n.out_edges = []
 368: 
 369:     for e in edges.values():
 370:         nodes[e.src_node].out_edges.append(e.edge_id)
 371:         nodes[e.dst_node].in_edges.append(e.edge_id)
 372: 
 373: 
 374: def build_nodes_and_edges(
 375:     wires: Dict[int, Wire],
 376:     cells: List[CellIR],
 377: ) -> Tuple[Dict[str, DKGNode], Dict[str, DKGEdge]]:
 378:     connect_wires_to_cells(wires, cells)
 379: 
 380:     nodes: Dict[str, DKGNode] = {}
 381:     for cell in cells:
 382:         node_id = make_node_id(cell)
 383:         node = DKGNode(
 384:             node_id=node_id,
 385:             entity_class=map_cell_type(cell.type),
 386:             hier_path=cell.module,
 387:             local_name=cell.name,
 388:         )
 389:         node.canonical_name = make_node_canonical_name(node)
 390: 
 391:         file, line = parse_src(cell.src)
 392:         prov = Provenance(
 393:             origin_file=file,
 394:             origin_line=line,
 395:             tool_stage="rtl",
 396:             confidence="exact",
 397:         )
 398:         add_provenance(node, prov, make_primary=True)
 399:         nodes[node_id] = node
 400: 
 401:     edges: Dict[str, DKGEdge] = {}
 402:     eid = 0
 403: 
 404:     for w in wires.values():
 405:         for src in w.drivers:
 406:             for dst in w.loads:
 407:                 edge_id = f"e{eid}"
 408:                 eid += 1
 409: 
 410:                 edge = DKGEdge(
 411:                     edge_id=edge_id,
 412:                     src_node=src,
 413:                     dst_node=dst,
 414:                     relation_type=RelationType.DATA,
 415:                     flow_type=EdgeFlowType.COMBINATIONAL,
 416:                     signal_name=w.name or f"wire_{w.wire_id}",
 417:                     canonical_name=f"{src}->{dst}",
 418:                 )
 419: 
 420:                 file, line = parse_src(w.src)
 421:                 prov = Provenance(
 422:                     origin_file=file,
 423:                     origin_line=line,
 424:                     tool_stage="rtl",
 425:                     confidence="exact",
 426:                 )
 427:                 add_provenance(edge, prov, make_primary=True)
 428: 
 429:                 edges[edge_id] = edge
 430: 
 431:     edges = merge_bit_edges_to_bus(edges)
 432: 
 433:     new_edges: Dict[str, DKGEdge] = {}
 434:     for e in edges.values():
 435:         new_id = make_edge_id(e)
 436:         e.edge_id = new_id
 437:         new_edges[new_id] = e
 438: 
 439:     edges = new_edges
 440:     reindex_node_edges(nodes, edges)
 441: 
 442:     clock_nets, reset_nets = detect_clock_reset_signals(nodes, edges, cells, wires)
 443:     assign_clock_domains(nodes, edges, clock_nets)
 444:     assign_edge_flow_types(nodes, edges, clock_nets, reset_nets)
 445: 
 446:     return nodes, edges


================================================================================
FILE: dkg\graph_metadata.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from dataclasses import dataclass, field
   4: from typing import Any, Dict, Optional
   5: 
   6: from .stages import FieldSource, ParsingStage
   7: 
   8: 
   9: @dataclass
  10: class FieldMetadata:
  11:     """각 필드 값의 메타데이터"""
  12:     
  13:     value: Any
  14:     source: FieldSource
  15:     stage: ParsingStage
  16:     origin_file: Optional[str] = None
  17:     origin_line: Optional[int] = None
  18:     timestamp: Optional[float] = None  # 업데이트 시각
  19: 
  20: 
  21: @dataclass
  22: class NodeMetadata:
  23:     """노드의 모든 필드에 대한 메타데이터"""
  24:     
  25:     fields: Dict[str, FieldMetadata] = field(default_factory=dict)
  26:     
  27:     def get(self, field_name: str, default: Any = None) -> Any:
  28:         """필드 값 반환"""
  29:         if field_name in self.fields:
  30:             return self.fields[field_name].value
  31:         return default
  32:     
  33:     def get_source(self, field_name: str) -> Optional[FieldSource]:
  34:         """필드의 출처 반환"""
  35:         if field_name in self.fields:
  36:             return self.fields[field_name].source
  37:         return None
  38:     
  39:     def set(
  40:         self,
  41:         field_name: str,
  42:         value: Any,
  43:         source: FieldSource,
  44:         stage: ParsingStage,
  45:         origin_file: Optional[str] = None,
  46:         origin_line: Optional[int] = None,
  47:     ) -> None:
  48:         """필드 값 설정"""
  49:         self.fields[field_name] = FieldMetadata(
  50:             value=value,
  51:             source=source,
  52:             stage=stage,
  53:             origin_file=origin_file,
  54:             origin_line=origin_line,
  55:         )
  56:     
  57:     def should_update(self, field_name: str, new_source: FieldSource) -> bool:
  58:         """필드를 업데이트해야 하는지 판단"""
  59:         from .stages import should_update_field
  60:         
  61:         current_source = self.get_source(field_name)
  62:         return should_update_field(current_source, new_source)
  63: 
  64: 
  65: @dataclass
  66: class EdgeMetadata:
  67:     """엣지의 모든 필드에 대한 메타데이터"""
  68:     
  69:     fields: Dict[str, FieldMetadata] = field(default_factory=dict)
  70:     
  71:     def get(self, field_name: str, default: Any = None) -> Any:
  72:         if field_name in self.fields:
  73:             return self.fields[field_name].value
  74:         return default
  75:     
  76:     def get_source(self, field_name: str) -> Optional[FieldSource]:
  77:         if field_name in self.fields:
  78:             return self.fields[field_name].source
  79:         return None
  80:     
  81:     def set(
  82:         self,
  83:         field_name: str,
  84:         value: Any,
  85:         source: FieldSource,
  86:         stage: ParsingStage,
  87:         origin_file: Optional[str] = None,
  88:         origin_line: Optional[int] = None,
  89:     ) -> None:
  90:         self.fields[field_name] = FieldMetadata(
  91:             value=value,
  92:             source=source,
  93:             stage=stage,
  94:             origin_file=origin_file,
  95:             origin_line=origin_line,
  96:         )
  97:     
  98:     def should_update(self, field_name: str, new_source: FieldSource) -> bool:
  99:         from .stages import should_update_field
 100:         
 101:         current_source = self.get_source(field_name)
 102:         return should_update_field(current_source, new_source)


================================================================================
FILE: dkg\graph_updater.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from typing import Any, Dict, Optional
   4: 
   5: from .graph import DKGEdge, DKGNode
   6: from .graph_metadata import EdgeMetadata, NodeMetadata
   7: from .stages import FieldSource, ParsingStage
   8: 
   9: 
  10: class GraphUpdater:
  11:     """
  12:     그래프를 점진적으로 업데이트하는 엔진.
  13:     각 파싱 stage가 기존 그래프에 새 정보를 merge할 때 사용.
  14:     """
  15:     
  16:     def __init__(
  17:         self,
  18:         nodes: Dict[str, DKGNode],
  19:         edges: Dict[str, DKGEdge],
  20:     ):
  21:         self.nodes = nodes
  22:         self.edges = edges
  23:         
  24:         # 메타데이터 저장소 (node_id/edge_id -> metadata)
  25:         self.node_metadata: Dict[str, NodeMetadata] = {
  26:             nid: NodeMetadata() for nid in nodes
  27:         }
  28:         self.edge_metadata: Dict[str, EdgeMetadata] = {
  29:             eid: EdgeMetadata() for eid in edges
  30:         }
  31:     
  32:     def update_node_field(
  33:         self,
  34:         node_id: str,
  35:         field_name: str,
  36:         value: Any,
  37:         source: FieldSource,
  38:         stage: ParsingStage,
  39:         origin_file: Optional[str] = None,
  40:         origin_line: Optional[int] = None,
  41:     ) -> bool:
  42:         """
  43:         노드 필드를 업데이트.
  44:         
  45:         Returns:
  46:             True if updated, False if skipped (lower priority)
  47:         """
  48:         if node_id not in self.nodes:
  49:             return False
  50:         
  51:         meta = self.node_metadata[node_id]
  52:         
  53:         if not meta.should_update(field_name, source):
  54:             return False
  55:         
  56:         # 메타데이터 업데이트
  57:         meta.set(field_name, value, source, stage, origin_file, origin_line)
  58:         
  59:         # 실제 노드 객체 업데이트
  60:         if hasattr(self.nodes[node_id], field_name):
  61:             setattr(self.nodes[node_id], field_name, value)
  62:         
  63:         return True
  64:     
  65:     def update_edge_field(
  66:         self,
  67:         edge_id: str,
  68:         field_name: str,
  69:         value: Any,
  70:         source: FieldSource,
  71:         stage: ParsingStage,
  72:         origin_file: Optional[str] = None,
  73:         origin_line: Optional[int] = None,
  74:     ) -> bool:
  75:         """엣지 필드를 업데이트"""
  76:         if edge_id not in self.edges:
  77:             return False
  78:         
  79:         meta = self.edge_metadata[edge_id]
  80:         
  81:         if not meta.should_update(field_name, source):
  82:             return False
  83:         
  84:         meta.set(field_name, value, source, stage, origin_file, origin_line)
  85:         
  86:         if hasattr(self.edges[edge_id], field_name):
  87:             setattr(self.edges[edge_id], field_name, value)
  88:         
  89:         return True
  90:     
  91:     def batch_update_clock_domains(
  92:         self,
  93:         clock_assignments: Dict[str, str],  # node_id -> clock_domain
  94:         source: FieldSource,
  95:         stage: ParsingStage,
  96:         origin_file: Optional[str] = None,
  97:     ) -> int:
  98:         """클럭 도메인 일괄 업데이트"""
  99:         count = 0
 100:         for node_id, clock_domain in clock_assignments.items():
 101:             if self.update_node_field(
 102:                 node_id, "clock_domain", clock_domain, source, stage, origin_file
 103:             ):
 104:                 count += 1
 105:         return count
 106:     
 107:     def batch_update_timing_exceptions(
 108:         self,
 109:         exceptions: Dict[str, str],  # edge_id -> exception_type
 110:         source: FieldSource,
 111:         stage: ParsingStage,
 112:         origin_file: Optional[str] = None,
 113:     ) -> int:
 114:         """타이밍 예외 일괄 업데이트"""
 115:         count = 0
 116:         for edge_id, exception_type in exceptions.items():
 117:             if self.update_edge_field(
 118:                 edge_id, "timing_exception", exception_type, source, stage, origin_file
 119:             ):
 120:                 count += 1
 121:         return count
 122:     
 123:     def get_field_history(self, node_id: str, field_name: str) -> Optional[list]:
 124:         """필드의 변경 이력 반환 (향후 확장용)"""
 125:         # TODO: 이력 추적이 필요하면 metadata에 history 추가
 126:         pass
 127:     
 128:     def export_metadata_summary(self) -> dict:
 129:         """메타데이터 요약 반환 (디버깅/캐싱 용)"""
 130:         return {
 131:             "nodes": {
 132:                 nid: {
 133:                     field: {
 134:                         "source": meta.source.value,
 135:                         "stage": meta.stage.value,
 136:                     }
 137:                     for field, meta in nm.fields.items()
 138:                 }
 139:                 for nid, nm in self.node_metadata.items()
 140:             },
 141:             "edges": {
 142:                 eid: {
 143:                     field: {
 144:                         "source": meta.source.value,
 145:                         "stage": meta.stage.value,
 146:                     }
 147:                     for field, meta in em.fields.items()
 148:                 }
 149:                 for eid, em in self.edge_metadata.items()
 150:             },
 151:         }


================================================================================
FILE: dkg\ir.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from dataclasses import dataclass, field
   4: from typing import Optional
   5: 
   6: 
   7: @dataclass
   8: class Wire:
   9:     wire_id: int
  10:     name: str | None = None
  11:     drivers: list[str] = field(default_factory=list)
  12:     loads: list[str] = field(default_factory=list)
  13:     src: Optional[str] = None
  14: 
  15: 
  16: @dataclass
  17: class CellIR:
  18:     name: str
  19:     type: str
  20:     module: str
  21:     port_dirs: dict[str, str]
  22:     connections: dict[str, list[int]]
  23:     src: Optional[str] = None


================================================================================
FILE: dkg\parsers\sdc_parser.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: import re
   4: from typing import Dict
   5: 
   6: from ..graph import DKGEdge, DKGNode
   7: from ..graph_updater import GraphUpdater
   8: from ..stages import FieldSource, ParsingStage
   9: from . import ConstraintParser
  10: 
  11: 
  12: class SdcParser(ConstraintParser):
  13:     """
  14:     SDC (Synopsys Design Constraints) 파서.
  15:     
  16:     처리하는 명령:
  17:     - create_clock: 클럭 정의
  18:     - set_input_delay / set_output_delay: I/O 타이밍
  19:     - set_false_path: false path 제약
  20:     - set_multicycle_path: multicycle 제약
  21:     - set_max_delay / set_min_delay: 지연 제약
  22:     """
  23:     
  24:     def get_stage(self) -> ParsingStage:
  25:         return ParsingStage.CONSTRAINTS
  26:     
  27:     def parse_and_update(
  28:         self,
  29:         filepath: str,
  30:         updater: GraphUpdater,
  31:         nodes: Dict[str, DKGNode],
  32:         edges: Dict[str, DKGEdge],
  33:     ) -> None:
  34:         with open(filepath, "r", encoding="utf-8") as f:
  35:             lines = f.readlines()
  36:         
  37:         for line_num, line in enumerate(lines, start=1):
  38:             line = line.strip()
  39:             
  40:             # create_clock 처리
  41:             if line.startswith("create_clock"):
  42:                 self._parse_create_clock(
  43:                     line, line_num, filepath, updater, nodes, edges
  44:                 )
  45:             
  46:             # set_false_path 처리
  47:             elif line.startswith("set_false_path"):
  48:                 self._parse_false_path(
  49:                     line, line_num, filepath, updater, edges
  50:                 )
  51:             
  52:             # set_multicycle_path 처리
  53:             elif line.startswith("set_multicycle_path"):
  54:                 self._parse_multicycle_path(
  55:                     line, line_num, filepath, updater, edges
  56:                 )
  57:     
  58:     def _parse_create_clock(
  59:         self,
  60:         line: str,
  61:         line_num: int,
  62:         filepath: str,
  63:         updater: GraphUpdater,
  64:         nodes: Dict[str, DKGNode],
  65:         edges: Dict[str, DKGEdge],
  66:     ) -> None:
  67:         """
  68:         create_clock 명령 파싱.
  69:         예: create_clock -name clk -period 10 [get_ports clk]
  70:         """
  71:         # 간단한 정규식 (실제로는 더 정교해야 함)
  72:         match = re.search(r"-name\s+(\w+)", line)
  73:         if not match:
  74:             return
  75:         
  76:         clock_name = match.group(1)
  77:         
  78:         # get_ports로 포트 이름 추출
  79:         port_match = re.search(r"get_ports\s+(\w+)", line)
  80:         if not port_match:
  81:             return
  82:         
  83:         port_name = port_match.group(1)
  84:         
  85:         # 해당 포트를 가진 노드들 찾기
  86:         for node_id, node in nodes.items():
  87:             if node.local_name == port_name:
  88:                 updater.update_node_field(
  89:                     node_id,
  90:                     "clock_domain",
  91:                     clock_name,
  92:                     FieldSource.DECLARED,
  93:                     ParsingStage.CONSTRAINTS,
  94:                     filepath,
  95:                     line_num,
  96:                 )
  97:         
  98:         # 해당 신호를 가진 엣지들도 업데이트
  99:         for edge_id, edge in edges.items():
 100:             if edge.signal_name == port_name:
 101:                 updater.update_edge_field(
 102:                     edge_id,
 103:                     "clock_signal",
 104:                     clock_name,
 105:                     FieldSource.DECLARED,
 106:                     ParsingStage.CONSTRAINTS,
 107:                     filepath,
 108:                     line_num,
 109:                 )
 110:     
 111:     def _parse_false_path(
 112:         self,
 113:         line: str,
 114:         line_num: int,
 115:         filepath: str,
 116:         updater: GraphUpdater,
 117:         edges: Dict[str, DKGEdge],
 118:     ) -> None:
 119:         """
 120:         set_false_path 명령 파싱.
 121:         예: set_false_path -from [get_pins src/*] -to [get_pins dst/*]
 122:         """
 123:         # 간단한 구현 (실제로는 -from/-to 파싱 필요)
 124:         # TODO: 실제 from/to 노드 매칭 로직 구현
 125:         
 126:         # 일단 placeholder
 127:         # affected_edges = find_edges_between(from_pattern, to_pattern)
 128:         # for edge_id in affected_edges:
 129:         #     updater.update_edge_field(...)
 130:         pass
 131:     
 132:     def _parse_multicycle_path(
 133:         self,
 134:         line: str,
 135:         line_num: int,
 136:         filepath: str,
 137:         updater: GraphUpdater,
 138:         edges: Dict[str, DKGEdge],
 139:     ) -> None:
 140:         """
 141:         set_multicycle_path 명령 파싱.
 142:         예: set_multicycle_path 2 -from [get_pins ...] -to [get_pins ...]
 143:         """
 144:         # TODO: 구현
 145:         pass


================================================================================
FILE: dkg\parsers\xdc_parser.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from typing import Dict
   4: 
   5: from ..graph import DKGEdge, DKGNode
   6: from ..graph_updater import GraphUpdater
   7: from ..stages import ParsingStage
   8: from . import ConstraintParser
   9: 
  10: 
  11: class XdcParser(ConstraintParser):
  12:     """
  13:     XDC (Xilinx Design Constraints) 파서.
  14:     
  15:     SDC와 유사하지만 Xilinx 특화 명령 포함:
  16:     - set_property LOC / IOSTANDARD: 핀 배치
  17:     - create_pblock: 물리적 블록 정의
  18:     """
  19:     
  20:     def get_stage(self) -> ParsingStage:
  21:         return ParsingStage.CONSTRAINTS
  22:     
  23:     def parse_and_update(
  24:         self,
  25:         filepath: str,
  26:         updater: GraphUpdater,
  27:         nodes: Dict[str, DKGNode],
  28:         edges: Dict[str, DKGEdge],
  29:     ) -> None:
  30:         # TODO: XDC 파싱 구현
  31:         # SDC 파서와 유사하지만 set_property 등 처리
  32:         pass


================================================================================
FILE: dkg\pipeline.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from pathlib import Path
   4: from typing import Dict, List, Optional
   5: 
   6: from .config import YosysConfig
   7: from .graph import DKGEdge, DKGNode
   8: from .graph_build import build_nodes_and_edges, build_wires_and_cells
   9: from .graph_updater import GraphUpdater
  10: from .parsers import ConstraintParser
  11: from .parsers.sdc_parser import SdcParser
  12: from .parsers.xdc_parser import XdcParser
  13: from .stages import FieldSource, ParsingStage
  14: from .yosys_parser import parse_yosys
  15: 
  16: 
  17: class DKGPipeline:
  18:     """
  19:     전체 DKG 구축 파이프라인.
  20:     
  21:     Usage:
  22:         pipeline = DKGPipeline(yosys_config)
  23:         
  24:         # Stage 1: RTL 파싱
  25:         pipeline.run_rtl_stage()
  26:         
  27:         # Stage 2: Constraint 추가
  28:         pipeline.add_constraints("design.sdc")
  29:         pipeline.add_constraints("design.xdc")
  30:         
  31:         # Stage 3: 타이밍 리포트 추가
  32:         pipeline.add_timing_report("timing.rpt")
  33:         
  34:         # 최종 그래프 반환
  35:         nodes, edges = pipeline.get_graph()
  36:     """
  37:     
  38:     def __init__(self, yosys_config: YosysConfig):
  39:         self.yosys_config = yosys_config
  40:         
  41:         self.nodes: Optional[Dict[str, DKGNode]] = None
  42:         self.edges: Optional[Dict[str, DKGEdge]] = None
  43:         self.updater: Optional[GraphUpdater] = None
  44:         
  45:         self.current_stage = None
  46:         self.completed_stages: List[ParsingStage] = []
  47:         
  48:         # 파서 레지스트리
  49:         self.parsers: Dict[str, ConstraintParser] = {
  50:             "sdc": SdcParser(),
  51:             "xdc": XdcParser(),
  52:             # TODO: 추가 파서 등록
  53:         }
  54:     
  55:     def run_rtl_stage(self) -> None:
  56:         """Stage 1: RTL 파싱 (Yosys)"""
  57:         yosys = parse_yosys(self.yosys_config)
  58:         wires, cells = build_wires_and_cells(yosys)
  59:         self.nodes, self.edges = build_nodes_and_edges(wires, cells)
  60:         
  61:         self.updater = GraphUpdater(self.nodes, self.edges)
  62:         self.current_stage = ParsingStage.RTL
  63:         self.completed_stages.append(ParsingStage.RTL)
  64:         
  65:         # 초기 메타데이터 설정 (모두 INFERRED)
  66:         self._mark_initial_fields_as_inferred()
  67:     
  68:     def add_constraints(self, filepath: str) -> None:
  69:         """Stage 2: Constraint 파일 추가"""
  70:         if self.updater is None or self.nodes is None or self.edges is None:
  71:             raise RuntimeError("RTL stage must be run first")
  72:         
  73:         # 파일 확장자로 파서 선택
  74:         ext = Path(filepath).suffix.lower().lstrip(".")
  75:         
  76:         if ext not in self.parsers:
  77:             raise ValueError(f"Unsupported constraint format: {ext}")
  78:         
  79:         parser = self.parsers[ext]
  80:         parser.parse_and_update(filepath, self.updater, self.nodes, self.edges)
  81:         
  82:         if ParsingStage.CONSTRAINTS not in self.completed_stages:
  83:             self.completed_stages.append(ParsingStage.CONSTRAINTS)
  84:     
  85:     def add_timing_report(self, filepath: str) -> None:
  86:         """Stage 3: 타이밍 리포트 추가"""
  87:         # TODO: 타이밍 리포트 파서 구현
  88:         pass
  89:     
  90:     def add_floorplan(self, filepath: str) -> None:
  91:         """Stage 4: Floorplan TCL 추가"""
  92:         # TODO: TCL 파서 구현
  93:         pass
  94:     
  95:     def get_graph(self) -> tuple[Dict[str, DKGNode], Dict[str, DKGEdge]]:
  96:         """최종 그래프 반환"""
  97:         if self.nodes is None or self.edges is None:
  98:             raise RuntimeError("No graph available. Run RTL stage first.")
  99:         return self.nodes, self.edges
 100:     
 101:     def get_updater(self) -> GraphUpdater:
 102:         """GraphUpdater 반환 (고급 사용자용)"""
 103:         if self.updater is None:
 104:             raise RuntimeError("No updater available. Run RTL stage first.")
 105:         return self.updater
 106:     
 107:     def export_metadata(self) -> dict:
 108:         """메타데이터 요약 반환 (캐싱/디버깅용)"""
 109:         if self.updater is None:
 110:             return {}
 111:         return self.updater.export_metadata_summary()
 112:     
 113:     def _mark_initial_fields_as_inferred(self) -> None:
 114:         """RTL stage에서 추론한 필드들을 INFERRED로 마킹"""
 115:         if self.nodes is None or self.edges is None or self.updater is None:
 116:             return
 117:         
 118:         # clock_domain, flow_type 등 휴리스틱으로 채운 필드들
 119:         for node_id, node in self.nodes.items():
 120:             if node.clock_domain:
 121:                 self.updater.node_metadata[node_id].set(
 122:                     "clock_domain",
 123:                     node.clock_domain,
 124:                     FieldSource.INFERRED,
 125:                     ParsingStage.RTL,
 126:                 )
 127:         
 128:         for edge_id, edge in self.edges.items():
 129:             if edge.flow_type:
 130:                 self.updater.edge_metadata[edge_id].set(
 131:                     "flow_type",
 132:                     edge.flow_type.value,
 133:                     FieldSource.INFERRED,
 134:                     ParsingStage.RTL,
 135:                 )


================================================================================
FILE: dkg\provenance.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from dataclasses import dataclass
   4: from typing import Iterable, Optional, Tuple, List
   5: 
   6: 
   7: @dataclass
   8: class Provenance:
   9:     origin_file: Optional[str] = None
  10:     origin_line: Optional[int] = None
  11:     tool_stage: str = "rtl"  # rtl / synth / timing / constraint
  12:     confidence: str = "exact"  # exact / inferred
  13: 
  14: 
  15: def add_provenance(obj, prov: Provenance, make_primary: bool = False) -> None:
  16:     obj.provenances.append(prov)
  17:     if make_primary or obj.primary_provenance is None:
  18:         obj.primary_provenance = prov
  19: 
  20: 
  21: def merge_provenances_nodes(nodes: Iterable) -> Tuple[Provenance, List[Provenance]]:
  22:     new_provs: List[Provenance] = []
  23:     for n in nodes:
  24:         new_provs.extend(n.provenances)
  25: 
  26:     files = [p.origin_file for p in new_provs if p.origin_file]
  27:     lines = [p.origin_line for p in new_provs if p.origin_line]
  28: 
  29:     primary = Provenance(
  30:         origin_file=files[0] if files else None,
  31:         origin_line=min(lines) if lines else None,
  32:         tool_stage="rtl",
  33:         confidence="inferred",
  34:     )
  35: 
  36:     return primary, new_provs
  37: 
  38: 
  39: def merge_provenances_edges(edges: Iterable) -> Tuple[Provenance, List[Provenance]]:
  40:     new_provs: List[Provenance] = []
  41:     for e in edges:
  42:         new_provs.extend(e.provenances)
  43: 
  44:     files = [p.origin_file for p in new_provs if p.origin_file]
  45:     lines = [p.origin_line for p in new_provs if p.origin_line]
  46: 
  47:     primary = Provenance(
  48:         origin_file=files[0] if files else None,
  49:         origin_line=min(lines) if lines else None,
  50:         tool_stage="rtl",
  51:         confidence="inferred",
  52:     )
  53: 
  54:     return primary, new_provs


================================================================================
FILE: dkg\stages.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from enum import Enum
   4: from typing import FrozenSet
   5: 
   6: 
   7: class ParsingStage(str, Enum):
   8:     """파싱 단계 정의. 순서대로 실행됨."""
   9:     
  10:     RTL = "rtl"                    # Yosys JSON (구조 정보)
  11:     SYNTHESIS = "synthesis"        # 합성 후 netlist
  12:     CONSTRAINTS = "constraints"    # SDC/XDC (타이밍/클럭 제약)
  13:     FLOORPLAN = "floorplan"        # TCL/Pblock (물리적 배치)
  14:     TIMING = "timing"              # 타이밍 리포트
  15:     BOARD = "board"                # BD/board constraints
  16: 
  17: 
  18: class FieldSource(str, Enum):
  19:     """필드 값의 출처"""
  20:     
  21:     INFERRED = "inferred"          # 휴리스틱으로 추론
  22:     DECLARED = "declared"          # 명시적으로 선언됨
  23:     ANALYZED = "analyzed"          # 도구 분석 결과
  24:     USER_OVERRIDE = "user_override"  # 사용자 직접 설정
  25: 
  26: 
  27: # 각 필드가 어느 stage에서 확정되는지 정의
  28: FIELD_STAGES: dict[str, FrozenSet[ParsingStage]] = {
  29:     # Node fields
  30:     "entity_class": frozenset([ParsingStage.RTL, ParsingStage.SYNTHESIS]),
  31:     "hier_path": frozenset([ParsingStage.RTL, ParsingStage.SYNTHESIS]),
  32:     "clock_domain": frozenset([ParsingStage.RTL, ParsingStage.CONSTRAINTS]),
  33:     "arrival_time": frozenset([ParsingStage.TIMING]),
  34:     "required_time": frozenset([ParsingStage.TIMING]),
  35:     "slack": frozenset([ParsingStage.TIMING]),
  36:     
  37:     # Edge fields
  38:     "signal_name": frozenset([ParsingStage.RTL, ParsingStage.SYNTHESIS]),
  39:     "flow_type": frozenset([ParsingStage.RTL, ParsingStage.CONSTRAINTS]),
  40:     "clock_signal": frozenset([ParsingStage.CONSTRAINTS]),
  41:     "reset_signal": frozenset([ParsingStage.CONSTRAINTS]),
  42:     "delay": frozenset([ParsingStage.TIMING]),
  43:     "timing_exception": frozenset([ParsingStage.CONSTRAINTS]),
  44: }
  45: 
  46: 
  47: def get_priority(source: FieldSource) -> int:
  48:     """값 우선순위. 높을수록 신뢰도 높음."""
  49:     priorities = {
  50:         FieldSource.INFERRED: 1,
  51:         FieldSource.DECLARED: 3,
  52:         FieldSource.ANALYZED: 2,
  53:         FieldSource.USER_OVERRIDE: 4,
  54:     }
  55:     return priorities[source]
  56: 
  57: 
  58: def should_update_field(
  59:     current_source: FieldSource | None,
  60:     new_source: FieldSource,
  61: ) -> bool:
  62:     """기존 값을 새 값으로 업데이트할지 결정"""
  63:     if current_source is None:
  64:         return True
  65:     return get_priority(new_source) >= get_priority(current_source)


================================================================================
FILE: dkg\supergraph.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: from dataclasses import dataclass, field
   4: from enum import Enum
   5: from typing import Any, Dict, List, Optional, Set, Tuple
   6: 
   7: from .graph import DKGEdge, DKGNode, EdgeFlowType, EntityClass, RelationType
   8: from .provenance import Provenance
   9: from .utils import stable_hash
  10: 
  11: 
  12: class GraphViewType(str, Enum):
  13:     Structural = "Structural"
  14:     Timing = "Timing"
  15:     Connectivity = "Connectivity"
  16:     Physical = "Physical"
  17: 
  18: 
  19: class SuperClass(str, Enum):
  20:     ATOMIC = "Atomic"
  21:     MODULE_CLUSTER = "ModuleCluster"
  22:     SEQ_CHAIN = "SequentialChain"
  23:     COMB_CLOUD = "CombinationalCloud"
  24:     IO_CLUSTER = "IOCluster"
  25:     CONSTRAINT_GROUP = "ConstraintGroup"
  26:     CRITICAL_REGION = "CriticalRegion"
  27:     SLACK_REGION = "SlackRegion"
  28:     ELIMINATED = "EliminatedNode"
  29: 
  30: 
  31: class NodeAction(Enum):
  32:     PROMOTE = "promote"
  33:     MERGE = "merge"
  34:     ELIMINATE = "eliminate"
  35: 
  36: 
  37: @dataclass
  38: class SuperNode:
  39:     node_id: str
  40:     super_class: SuperClass
  41:     member_nodes: Set[str]
  42:     member_edges: Set[str]
  43:     aggregated_attrs: Dict[str, Any] = field(default_factory=dict)
  44:     provenances: List[Provenance] = field(default_factory=list)
  45:     canonical_name: Optional[str] = None
  46:     display_name: Optional[str] = None
  47: 
  48: 
  49: @dataclass
  50: class SuperEdge:
  51:     edge_id: str
  52:     src_node: str
  53:     dst_node: str
  54:     member_edges: Set[str]
  55:     member_nodes: Set[str]
  56:     relation_types: Set[RelationType]
  57:     flow_types: Set[EdgeFlowType]
  58:     provenances: List[Provenance] = field(default_factory=list)
  59:     canonical_name: Optional[str] = None
  60:     display_name: Optional[str] = None
  61: 
  62: 
  63: @dataclass
  64: class SuperGraph:
  65:     super_nodes: Dict[str, SuperNode]
  66:     super_edges: Dict[Tuple[str, str], SuperEdge]
  67:     node_to_super: Dict[str, str]
  68: 
  69: 
  70: def make_supernode_canonical_name(sn: SuperNode, nodes: Dict[str, DKGNode]) -> str:
  71:     any_node = nodes[next(iter(sn.member_nodes))]
  72:     base = any_node.hier_path
  73:     return f"{base} : {sn.super_class.value}"
  74: 
  75: 
  76: def make_supernode_display_name(sn: SuperNode) -> str:
  77:     if sn.super_class == SuperClass.COMB_CLOUD:
  78:         return "Combinational Logic"
  79:     if sn.super_class == SuperClass.SEQ_CHAIN:
  80:         return "Sequential Chain"
  81:     if sn.super_class == SuperClass.ATOMIC:
  82:         return "Block"
  83:     if sn.super_class == SuperClass.ELIMINATED:
  84:         return "Collapsed"
  85:     return sn.super_class.value
  86: 
  87: 
  88: def make_superedge_canonical_name(se: SuperEdge, super_nodes: Dict[str, SuperNode]) -> str:
  89:     src = super_nodes[se.src_node].canonical_name
  90:     dst = super_nodes[se.dst_node].canonical_name
  91:     return f"{src} -> {dst}"
  92: 
  93: 
  94: def make_superedge_display_name(se: SuperEdge) -> str:
  95:     if len(se.relation_types) == 1:
  96:         return next(iter(se.relation_types)).value.replace("Relation", "")
  97:     return "Multiple Signals"
  98: 
  99: 
 100: def supernode_signature(
 101:     view: GraphViewType,
 102:     super_class: SuperClass,
 103:     member_node_ids: set[str],
 104:     policy_version: str = "v1",
 105: ) -> str:
 106:     nodes_part = ",".join(sorted(member_node_ids))
 107:     return "|".join([view.value, super_class.value, policy_version, nodes_part])
 108: 
 109: 
 110: def make_supernode_id(
 111:     view: GraphViewType,
 112:     super_class: SuperClass,
 113:     member_node_ids: set[str],
 114:     policy_version: str = "v1",
 115: ) -> str:
 116:     sig = supernode_signature(view, super_class, member_node_ids, policy_version)
 117:     h = stable_hash(sig)
 118:     return f"SN_{view.value}_{super_class.value}_{h}"
 119: 
 120: 
 121: def superedge_signature(
 122:     src_sn: str,
 123:     dst_sn: str,
 124:     member_edge_ids: set[str],
 125:     policy_version: str = "v1",
 126: ) -> str:
 127:     edges_part = ",".join(sorted(member_edge_ids))
 128:     return "|".join([src_sn, dst_sn, policy_version, edges_part])
 129: 
 130: 
 131: def make_superedge_id(
 132:     src_sn: str,
 133:     dst_sn: str,
 134:     member_edge_ids: set[str],
 135:     policy_version: str = "v1",
 136: ) -> str:
 137:     sig = superedge_signature(src_sn, dst_sn, member_edge_ids, policy_version)
 138:     h = stable_hash(sig)
 139:     return f"SE_{h}"
 140: 
 141: 
 142: VIEW_POLICY: Dict[GraphViewType, Dict[EntityClass, NodeAction]] = {
 143:     GraphViewType.Structural: {
 144:         EntityClass.MODULE_INSTANCE: NodeAction.PROMOTE,
 145:         EntityClass.FLIP_FLOP: NodeAction.MERGE,
 146:         EntityClass.LUT: NodeAction.MERGE,
 147:         EntityClass.MUX: NodeAction.MERGE,
 148:         EntityClass.DSP: NodeAction.MERGE,
 149:         EntityClass.BRAM: NodeAction.MERGE,
 150:         EntityClass.IO_PORT: NodeAction.PROMOTE,
 151:         EntityClass.PACKAGE_PIN: NodeAction.ELIMINATE,
 152:         EntityClass.PBLOCK: NodeAction.ELIMINATE,
 153:     },
 154:     GraphViewType.Connectivity: {
 155:         EntityClass.FLIP_FLOP: NodeAction.PROMOTE,
 156:         EntityClass.DSP: NodeAction.PROMOTE,
 157:         EntityClass.BRAM: NodeAction.PROMOTE,
 158:         EntityClass.LUT: NodeAction.MERGE,
 159:         EntityClass.MUX: NodeAction.MERGE,
 160:         EntityClass.MODULE_INSTANCE: NodeAction.ELIMINATE,
 161:     },
 162: }
 163: 
 164: 
 165: class ViewBuilder:
 166:     def __init__(self, nodes: Dict[str, DKGNode], edges: Dict[str, DKGEdge], view: GraphViewType):
 167:         self.nodes = nodes
 168:         self.edges = edges
 169:         self.view = view
 170: 
 171:         self.node_to_super: Dict[str, str] = {}
 172:         self.super_nodes: Dict[str, SuperNode] = {}
 173:         self.super_edges: Dict[Tuple[str, str], SuperEdge] = {}
 174: 
 175:     def _neighbors_1hop(self, nid: str) -> Set[str]:
 176:         n = self.nodes[nid]
 177:         nbrs = set()
 178:         for eid in n.in_edges + n.out_edges:
 179:             e = self.edges[eid]
 180:             nbrs.add(e.src_node)
 181:             nbrs.add(e.dst_node)
 182:         return nbrs
 183: 
 184:     def cycle1_promote(self) -> None:
 185:         for n in self.nodes.values():
 186:             if VIEW_POLICY[self.view].get(n.entity_class) != NodeAction.PROMOTE:
 187:                 continue
 188: 
 189:             sn = SuperNode(
 190:                 node_id=f"SN_{n.node_id}",
 191:                 super_class=SuperClass.ATOMIC,
 192:                 member_nodes={n.node_id},
 193:                 member_edges=set(),
 194:                 provenances=list(n.provenances),
 195:             )
 196:             sn.canonical_name = make_supernode_canonical_name(sn, self.nodes)
 197:             sn.display_name = make_supernode_display_name(sn)
 198:             self.super_nodes[sn.node_id] = sn
 199:             self.node_to_super[n.node_id] = sn.node_id
 200: 
 201:     def cycle2_merge(self) -> None:
 202:         merge_candidates = {
 203:             nid
 204:             for nid, n in self.nodes.items()
 205:             if VIEW_POLICY[self.view].get(n.entity_class) == NodeAction.MERGE
 206:         }
 207: 
 208:         visited: Set[str] = set()
 209: 
 210:         for nid in merge_candidates:
 211:             if nid in visited:
 212:                 continue
 213: 
 214:             stack = [nid]
 215:             component: Set[str] = set()
 216: 
 217:             while stack:
 218:                 cur = stack.pop()
 219:                 if cur in visited or cur not in merge_candidates:
 220:                     continue
 221: 
 222:                 visited.add(cur)
 223:                 component.add(cur)
 224: 
 225:                 for nb in self._neighbors_1hop(cur):
 226:                     stack.append(nb)
 227: 
 228:             if not component:
 229:                 continue
 230: 
 231:             sn_id = make_supernode_id(
 232:                 view=self.view,
 233:                 super_class=SuperClass.COMB_CLOUD,
 234:                 member_node_ids=component,
 235:                 policy_version="v1",
 236:             )
 237: 
 238:             sn = SuperNode(
 239:                 node_id=sn_id,
 240:                 super_class=SuperClass.COMB_CLOUD,
 241:                 member_nodes=component,
 242:                 member_edges=set(),
 243:             )
 244:             sn.canonical_name = make_supernode_canonical_name(sn, self.nodes)
 245:             sn.display_name = make_supernode_display_name(sn)
 246: 
 247:             self.super_nodes[sn.node_id] = sn
 248:             for n in component:
 249:                 self.node_to_super[n] = sn.node_id
 250: 
 251:     def cycle2_5_eliminate(self) -> None:
 252:         for nid, n in self.nodes.items():
 253:             if nid in self.node_to_super:
 254:                 continue
 255: 
 256:             if VIEW_POLICY[self.view].get(n.entity_class) != NodeAction.ELIMINATE:
 257:                 raise RuntimeError(f"Unassigned node in view {self.view}: {nid}")
 258: 
 259:             sn = SuperNode(
 260:                 node_id=make_supernode_id(
 261:                     view=self.view,
 262:                     super_class=SuperClass.ELIMINATED,
 263:                     member_node_ids={nid},
 264:                     policy_version="v1",
 265:                 ),
 266:                 super_class=SuperClass.ELIMINATED,
 267:                 member_nodes={nid},
 268:                 member_edges=set(),
 269:             )
 270:             sn.canonical_name = make_supernode_canonical_name(sn, self.nodes)
 271:             sn.display_name = make_supernode_display_name(sn)
 272: 
 273:             self.super_nodes[sn.node_id] = sn
 274:             self.node_to_super[nid] = sn.node_id
 275: 
 276:     def cycle3_rewrite_edges(self) -> None:
 277:         for e in self.edges.values():
 278:             src_sn = self.node_to_super[e.src_node]
 279:             dst_sn = self.node_to_super[e.dst_node]
 280: 
 281:             if src_sn == dst_sn:
 282:                 self.super_nodes[src_sn].member_edges.add(e.edge_id)
 283:                 continue
 284: 
 285:             key = (src_sn, dst_sn)
 286:             if key not in self.super_edges:
 287:                 self.super_edges[key] = SuperEdge(
 288:                     edge_id=make_superedge_id(src_sn, dst_sn, set()),
 289:                     src_node=src_sn,
 290:                     dst_node=dst_sn,
 291:                     member_edges=set(),
 292:                     member_nodes=set(),
 293:                     relation_types=set(),
 294:                     flow_types=set(),
 295:                     provenances=[],
 296:                 )
 297:                 self.super_edges[key].canonical_name = make_superedge_canonical_name(
 298:                     self.super_edges[key],
 299:                     self.super_nodes,
 300:                 )
 301:                 self.super_edges[key].display_name = make_superedge_display_name(
 302:                     self.super_edges[key],
 303:                 )
 304: 
 305:             se = self.super_edges[key]
 306:             se.member_edges.add(e.edge_id)
 307:             se.member_nodes.update({e.src_node, e.dst_node})
 308:             se.relation_types.add(e.relation_type)
 309:             se.flow_types.add(e.flow_type)
 310:             se.provenances.extend(e.provenances)
 311: 
 312:     def build(self) -> SuperGraph:
 313:         self.cycle1_promote()
 314:         self.cycle2_merge()
 315:         self.cycle2_5_eliminate()
 316:         self.cycle3_rewrite_edges()
 317: 
 318:         return SuperGraph(
 319:             super_nodes=self.super_nodes,
 320:             super_edges=self.super_edges,
 321:             node_to_super=self.node_to_super,
 322:         )


================================================================================
FILE: dkg\utils.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: import hashlib
   4: import re
   5: from pathlib import Path
   6: from typing import Optional, Tuple
   7: 
   8: 
   9: def is_clock_name(name: str) -> bool:
  10:     n = name.lower()
  11:     return n == "clk" or n.startswith("clk") or n.endswith("_clk") or "clock" in n
  12: 
  13: 
  14: def is_reset_name(name: str) -> bool:
  15:     n = name.lower()
  16:     return n == "rst" or n.startswith("rst") or n.startswith("reset")
  17: 
  18: 
  19: def is_active_low(name: str) -> bool:
  20:     return name.lower().endswith("_n")
  21: 
  22: 
  23: def is_ff_cell(cell_type: str) -> bool:
  24:     return cell_type in {"$dff", "$adff", "$sdff", "$dffe", "$sdffe"}
  25: 
  26: 
  27: def is_async_reset_ff(cell_type: str) -> bool:
  28:     return cell_type == "$adff"
  29: 
  30: 
  31: def is_sync_reset_ff(cell_type: str) -> bool:
  32:     return cell_type == "$sdff"
  33: 
  34: 
  35: def win_to_wsl_path(win_path: str) -> str:
  36:     p = Path(win_path).resolve()
  37:     drive = p.drive[0].lower()
  38:     path_no_drive = p.as_posix()[2:]
  39:     return f"/mnt/{drive}{path_no_drive}"
  40: 
  41: 
  42: def parse_src(src_str: Optional[str]) -> Tuple[Optional[str], Optional[int]]:
  43:     if not src_str:
  44:         return None, None
  45:     try:
  46:         file_part, line_part = src_str.split(":")
  47:         line = int(line_part.split(".")[0])
  48:         return file_part, line
  49:     except Exception:
  50:         return None, None
  51: 
  52: 
  53: def split_signal_bit(sig: str) -> Tuple[str, Optional[int]]:
  54:     m = re.match(r"(.+)\[(\d+)\]$", sig)
  55:     if m:
  56:         return m.group(1), int(m.group(2))
  57:     return sig, None
  58: 
  59: 
  60: def stable_hash(s: str, length: int = 12) -> str:
  61:     return hashlib.sha1(s.encode()).hexdigest()[:length]


================================================================================
FILE: dkg\yosys_parser.py
================================================================================
   1: from __future__ import annotations
   2: 
   3: import glob
   4: import json
   5: import os
   6: import subprocess
   7: from pathlib import Path
   8: from typing import List
   9: 
  10: from .config import YosysConfig
  11: from .utils import win_to_wsl_path
  12: 
  13: 
  14: def collect_hdl_files(src_dir_win: str) -> List[str]:
  15:     verilog_files = glob.glob(os.path.join(src_dir_win, "*.v"))
  16:     sv_files = glob.glob(os.path.join(src_dir_win, "*.sv"))
  17:     return verilog_files + sv_files
  18: 
  19: 
  20: def build_yosys_script(files_wsl: List[str], top_module: str, out_json_wsl: str) -> str:
  21:     return "\n".join(
  22:         [
  23:             f"read_verilog -sv {' '.join(files_wsl)};",
  24:             f"hierarchy -check -top {top_module};",
  25:             "proc;",
  26:             "opt;",
  27:             f"write_json {out_json_wsl}",
  28:         ]
  29:     )
  30: 
  31: 
  32: def run_yosys(files_win: List[str], config: YosysConfig) -> None:
  33:     if not files_win:
  34:         raise RuntimeError("No HDL files found.")
  35: 
  36:     files_wsl = [win_to_wsl_path(f) for f in files_win]
  37:     out_json_wsl = win_to_wsl_path(config.out_json_win)
  38:     yosys_script = build_yosys_script(files_wsl, config.top_module, out_json_wsl)
  39: 
  40:     subprocess.run(["wsl", "yosys", "-p", yosys_script], check=True)
  41: 
  42: 
  43: def load_yosys_json(out_json_win: str) -> dict:
  44:     with open(out_json_win, "r", encoding="utf-8") as f:
  45:         return json.load(f)
  46: 
  47: 
  48: def parse_yosys(config: YosysConfig) -> dict:
  49:     files_win = collect_hdl_files(config.src_dir_win)
  50:     run_yosys(files_win, config)
  51:     return load_yosys_json(config.out_json_win)


